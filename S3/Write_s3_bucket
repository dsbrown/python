# This program writes to an S3 bucket
#

#for item in read_list:
#print read_list

access_key= '' # your AWS access key
secret_key = '' # your AWS secret key

source_path = "/home/local/ANT/eshelman/Documents/ReportCharts/Rackdown" # primary path to directory holding files/folders
source_path2 = source_path + "/daily.svg" #specific file 1
source_path3 = source_path + "/LSE_Report.svg" # specific file 2

conn = s3con(access_key, secret_key, is_secure=False,) # is_secure is most important for pushing files out; without this, I experience several error messages
bucket =  conn.get_bucket('rackdown-report') # This only works at the bucket level. Files/sub-folders need to be identified at the key level.

k = Key(bucket)

k.key = '/daily_rackdown.svg' # Here is where you would identify sub-folders if you have files stored in them.
k.set_contents_from_filename(source_path2)
k.make_public() # Boto will let you set the file as public at the time of storage, so you don't have to go back into you instance and reset it.

k.key = '/LSE_Report.svg'
k.set_contents_from_filename(source_path3)
k.make_public()

print "complete" # I use this as a flag to show that it has run. This message also appears in emails with crontabs, so I can specify which push has run.